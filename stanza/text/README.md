# text

Package for manipulating text.

## text.vocab.Vocab

An abstraction for a vocabulary object that maps between word tokens and indices.

```python
In [10]: v = Vocab('UNK')

In [11]: v.add('the') # add a single word and return the index
Out[11]: 1

In [12]: v.word2index['the']
Out[12]: 1

In [13]: v.index2word[0]
Out[13]: 'UNK'

In [14]: v.words2indices(['the', 'cat', 'is', 'out'], add=True) # add multiple words and return the indices
Out[14]: [1, 2, 3, 4]

In [15]: v.words2indices('the cat is out of the bag'.split()) # convert words to indices
Out[15]: [1, 2, 3, 4, 0, 1, 0]

In [16]: v.indices2words([0, 1, 2, 3])
Out[16]: ['UNK', 'the', 'cat', 'is']

In [17]: v['is']
Out[17]: 3
```


## text.vocab.SennaVocab

```python
In [4]: v = SennaVocab()

In [5]: v.words2indices('here are some words'.split(), add=True)
Out[5]: [1, 2, 3, 4]

In [6]: v.word2index
Out[6]: {'UNKNOWN': 0, 'are': 2, 'here': 1, 'some': 3, 'words': 4}

In [7]: E = v.get_embeddings() # you can use this to populate your lookup table

In [10]: for w in v.index2word: print(w, E[v[w]])
('UNKNOWN', array([-0.248583  ,  0.376111  ,  0.219852  ,  0.285336  ,  0.652333  ,
       -1.89169   , -1.00602   , -0.0393217 ,  0.365848  ,  1.41776   ,
        0.257446  , -0.122911  ,  0.746489  , -0.388436  , -0.895002  ,
       -0.00375268,  1.06132   , -0.846757  , -1.42469   , -1.69669   ,
        0.76299   , -0.705012  , -0.228695  ,  0.231346  , -0.407349  ,
       -0.380853  , -0.940169  , -1.64561   , -0.172944  ,  2.58849   ,
        0.824664  ,  0.733721  ,  1.91178   ,  0.445658  ,  0.691033  ,
       -0.518921  ,  1.88388   , -2.58745   , -0.343491  , -0.287059  ,
        1.34021   , -0.203886  , -0.453382  ,  1.51963   , -1.09819   ,
       -0.134222  ,  1.2711    , -0.326216  , -2.37616   , -0.341738  ]))
('here', array([-0.0440025, -0.397654 , -0.93615  ,  0.0291732, -0.685966 ,
       -1.48814  ,  1.1063   ,  0.218713 , -0.0471834,  0.159164 ,
        0.914808 ,  1.293    , -0.993522 , -0.314385 ,  2.03163  ,
       -0.179984 , -0.159812 , -0.0756768, -0.266013 ,  1.73663  ,
        1.99675  , -0.287682 ,  0.35148  , -0.147743 , -1.07215  ,
        0.713282 ,  1.0465   ,  0.705198 ,  0.0128309,  1.04977  ,
        0.258439 ,  0.071498 , -0.603898 ,  0.871149 , -0.144075 ,
       -2.12692  ,  0.488767 ,  0.287564 , -0.354859 ,  0.915249 ,
       -1.08697  ,  0.84363  , -0.459033 , -0.186911 ,  1.27532  ,
       -1.22698  , -0.12351  , -1.28254  ,  0.847416 ,  1.3458   ]))
('are', array([-0.124494 ,  0.522494 , -1.63825  ,  1.19275  , -1.12995  ,
        1.34807  ,  0.256256 , -2.36997  , -0.67457  ,  0.33953  ,
       -2.23168  , -1.09074  ,  0.55473  ,  1.20675  ,  1.19863  ,
       -0.329147 ,  0.0957122, -1.01793  ,  1.28353  ,  0.042727 ,
        0.401687 , -0.528303 ,  0.17855  , -0.539966 , -0.276202 ,
        0.668546 , -0.419668 ,  0.865822 ,  0.371023 , -0.302899 ,
       -0.138791 ,  0.902011 , -0.410331 ,  0.0351244, -0.212655 ,
       -0.424723 , -1.20364  ,  1.29368  ,  1.11933  , -0.736813 ,
        2.12944  , -1.21457  ,  1.27041  , -0.735014 ,  0.827069 ,
       -0.745823 , -0.599062 ,  1.40353  ,  1.0729   ,  0.565201 ]))
('some', array([ 0.628754 , -0.708372 , -0.226598 ,  0.305579 , -0.835875 ,
       -0.545606 ,  0.889345 , -0.883496 , -1.11348  , -0.373288 ,
        0.252977 , -0.37926  ,  0.0805677,  0.80778  ,  0.590788 ,
        1.09135  , -2.07812  ,  0.926464 ,  0.367727 ,  0.770197 ,
       -0.624679 , -1.07755  , -0.0820307,  0.766633 ,  0.397137 ,
        1.80722  , -0.810287 ,  0.457781 , -0.16348  , -0.976334 ,
        0.189054 ,  0.737602 , -2.00852  , -0.0558663, -0.335822 ,
        0.28509  ,  0.109228 , -1.29659  ,  2.52406  ,  0.26333  ,
       -0.389417 ,  1.12468  , -0.49429  ,  0.297379 , -0.671344 ,
        0.642579 , -0.515911 , -1.11318  ,  1.8606   ,  0.495105 ]))
('words', array([ 0.564328  ,  0.00410001, -0.309302  ,  1.29096   ,  0.38927   ,
       -0.319244  , -0.0708709 , -2.81106   ,  0.572329  ,  0.455052  ,
        1.01653   , -1.23863   , -0.0173331 , -0.192103  ,  1.2534    ,
        0.55132   ,  0.79186   ,  0.023534  , -0.726153  ,  0.798124  ,
       -0.323625  ,  0.128678  ,  0.962537  , -0.488812  ,  0.715478  ,
       -2.23982   ,  1.05843   , -1.11632   ,  1.61371   , -1.17965   ,
       -0.381775  , -0.0492024 , -1.25482   ,  1.12783   ,  0.349291  ,
       -1.00902   , -1.36707   , -0.221287  , -1.29751   ,  0.3376    ,
       -1.71816   , -0.462719  , -0.82554   ,  0.4739    , -0.00290712,
        0.292862  ,  0.617549  , -0.825371  ,  1.04553   ,  1.59466   ]))
```

## text.vocab.GloveVocab

Same interface as `SennaVocab`. The speficiations for the different configurations of pretrained vectors can be found [here](http://nlp.stanford.edu/projects/glove/).
